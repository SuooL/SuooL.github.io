<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.6.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.6.0" color="#222">









<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.6.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="引言 逻辑斯谛回归（logistic regression）是统计学习中的经典分类算法。最大熵模型是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型（maximum entropy model). 逻辑斯谛回归模型与最大熵模型都是对数线性模型.">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="logistic 算法及其在手写数字识别的实践">
<meta property="og:url" content="https://suool.net/2018/09/05/logistic-mnist/index.html">
<meta property="og:site_name" content="SuooL&#39;s Blog">
<meta property="og:description" content="引言 逻辑斯谛回归（logistic regression）是统计学习中的经典分类算法。最大熵模型是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型（maximum entropy model). 逻辑斯谛回归模型与最大熵模型都是对数线性模型.">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2018/09/18/15362860576396.jpg">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2018/09/18/LR_8.png">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2018/09/18/15366230049078.jpg">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2018/09/18/15366242666868.jpg">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2018/09/18/15366229765258.jpg">
<meta property="og:updated_time" content="2019-03-01T06:36:19.971Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="logistic 算法及其在手写数字识别的实践">
<meta name="twitter:description" content="引言 逻辑斯谛回归（logistic regression）是统计学习中的经典分类算法。最大熵模型是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型（maximum entropy model). 逻辑斯谛回归模型与最大熵模型都是对数线性模型.">
<meta name="twitter:image" content="https://suool-bolg.b0.upaiyun.com/2018/09/18/15362860576396.jpg">



  <link rel="alternate" href="/atom.xml" title="SuooL's Blog" type="application/atom+xml">




  <link rel="canonical" href="https://suool.net/2018/09/05/logistic-mnist/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>logistic 算法及其在手写数字识别的实践 | SuooL's Blog</title>
  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-61498523-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-61498523-1');
</script>









  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SuooL's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <h1 class="site-subtitle" itemprop="description">蛰伏于盛夏 藏华于当春</h1>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    

    

    <a href="/" rel="section">首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    

    

    <a href="/about/" rel="section">关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    

    

    <a href="/tags/" rel="section">标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    

    

    <a href="/categories/" rel="section">分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    

    

    <a href="/archives/" rel="section">归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-commonweal">

    
    
    

    

    <a href="/404.html" rel="section">公益 404</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://suool.net/2018/09/05/logistic-mnist/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="SuooL">
      <meta itemprop="description" content="胡振生写字的地方">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SuooL's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">logistic 算法及其在手写数字识别的实践

              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-09-05 08:47:57" itemprop="dateCreated datePublished" datetime="2018-09-05T08:47:57+08:00">2018-09-05</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-01 14:36:19" itemprop="dateModified" datetime="2019-03-01T14:36:19+08:00">2019-03-01</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/05/logistic-mnist/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/2018/09/05/logistic-mnist/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/09/05/logistic-mnist/" class="leancloud_visitors" data-flag-title="logistic 算法及其在手写数字识别的实践">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数：</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">5.1k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">13 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="引言">引言</h2>
<p>逻辑斯谛回归（logistic regression）是统计学习中的经典分类算法。最大熵模型是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型（maximum entropy model). 逻辑斯谛回归模型与最大熵模型都是对数线性模型. <a id="more"></a></p>
<h2 id="逻辑斯谛回归模型">逻辑斯谛回归模型</h2>
<h3 id="sigmoid-函数">sigmoid 函数</h3>
<p>首先我们知道，线性回归的公式如下： <span class="math display">\[
z = \omega_0x_0+\omega_1x_1+\omega_2x_1+\cdots+\omega_nx_n = \omega^Tx \tag{1}
\]</span></p>
<p>其次在介绍逻辑斯谛回归模型之前，我们先引入sigmoid函数，其数学形式是： <span class="math display">\[
g(x) = \frac {1}{1+e^{-x}} \tag{2}
\]</span></p>
<p>函数曲线如下: <img src="https://suool-bolg.b0.upaiyun.com/2018/09/18/15362860576396.jpg"></p>
<p>从上图可以看到 sigmoid 函数是一个 s 形的曲线，它的取值在 [0, 1] 之间，在远离 0 的地方函数的值会很快接近 0/1 。在横坐标的大尺度下看，sigmoid 函数很类似阶跃函数。</p>
<h2 id="二项逻辑斯谛回归模型">二项逻辑斯谛回归模型</h2>
<p>一个机器学习的模型，实际上是把决策函数限定在某一组条件下，这组限定条件就决定了模型的假设空间。当然，我们还希望这组限定条件简单而合理。而逻辑回归模型所做的假设是：</p>
<p><span class="math display">\[
h_\omega(x)=\frac {1}{1+e^{-z}} = \frac {1}{1+e^{-\omega^T\cdot x}} \tag{3}
\]</span></p>
<p>其中， <span class="math display">\[
y = \frac {1}{1+e^{-x}}
\]</span></p>
<p>我们可以看到，Logistic Regression 算法是将线性函数的结果映射到了sigmoid函数中。</p>
<p>因此，为了实现 Logistic 回归分类器，我们可以在每个特征上都乘以一个回归系数（如公式1所示），然后把所有结果值相加，将这个总和代入 Sigmoid 函数中，进而得到一个范围在 0~1 之间的数值。任何大于 0.5 的数据被分入 1 类，小于 0.5 即被归入 0 类。所以，Logistic 回归也是一种概率估计，比如这里Sigmoid 函数得出的值为0.5，可以理解为给定数据和参数，数据被分入 1 类的概率为0.5。</p>
<p>模型的条件概率分布函数的一般写法如下 <span class="math display">\[
P(Y=1\mid x;\omega) = h_\omega(x) \tag{4}
\]</span> 及 <span class="math display">\[
P(Y=0 \mid x;\omega) = 1-h_\omega(x) \tag{5}
\]</span></p>
<p>其中 <span class="math inline">\(w = (w^1,w^2, \cdots, w^n, b)^T\)</span> 为权值向量, <span class="math inline">\(x=(x^1, x^2, \cdots, x^n, 1)^T\)</span> 为输入向量.</p>
<p>因此逻辑斯谛回归的对数几率为 <span class="math display">\[
log \frac {P(Y=1\mid x)}{1-P(Y=1\mid x)} = w \cdot x \tag{6}
\]</span></p>
<p>由此可知, 在二项逻辑斯谛回归模型中, 输出 Y=1 的对数几率是输入 x 的线性函数. 又由式(3)可知,线性函数的值越接近正无穷, 概率值就越接近1, 反之越接近0, 这样子的模型就是逻辑斯谛回归模型.</p>
<h3 id="参数求解之最大似然估计法">参数求解之最大似然估计法</h3>
<p>模型的数学形式确定后，剩下就是如何去求解模型中的参数。统计学中常用的一种方法是最大似然估计，即找到一组参数，使得在这组参数下，我们的数据的似然度（概率）越大.</p>
<p>首先通过式(4)及(5)确定的概率函数为： <span class="math display">\[
P(y\mid x;\omega) = (h_\omega(x))^y\cdot (1-h_\omega(x))^{1-y}
\]</span></p>
<p>因为样本数据相互独立，所以他们的联合分布可以表示为各边际分布的乘积，取似然函数为： <span class="math display">\[
\begin{align}
L(\omega) &amp;= \prod_{i=1}^n P(y^i \mid x^i; \omega) \\
&amp; = \prod_{i=1}^n (h_\omega(x^i))^{y^i}\cdot (1-h_\omega(x^i))^{1-y^i}
\end{align}
\]</span></p>
<p>取对数似然函数： <span class="math display">\[
l(\omega)= \log(L(\omega)) = \sum_{i=1}^m\log((h_\omega(x^i))^{y^i})+\log((1-h_\omega(x^i))^{1-y^i})
\]</span></p>
<p>最大似然估计就是要求使得<span class="math inline">\(l(\omega)\)</span>取最大值时候的<span class="math inline">\(\omega\)</span>，这里可以用显然可以用梯度上升法求解，同时，如果稍微做下变换： <span class="math display">\[
J(\omega) = - \frac{1}{n}l(\omega)
\]</span></p>
<p>因为乘了一个负的系数,然后就可以使用梯度下降算法进行求解了.</p>
<h3 id="梯度上升算法">梯度上升算法</h3>
<p>梯度上升算法的基本思想是:要找到某个函数的最大值, 最好的方法是沿着该函数的梯度方向探寻. 如果梯度记为 <span class="math inline">\(\nabla\)</span>, 那么函数 <span class="math inline">\(f(x,y)\)</span>的梯度表示为: <span class="math display">\[
\nabla f(x,y) = \begin{pmatrix}  \frac{\partial f(x,y)}{\partial x} \\
\frac{\partial f(x,y)}{\partial y} \end{pmatrix} 
\]</span></p>
<p>梯度上升算法的描述公式为: <span class="math display">\[
w:=w+\alpha \nabla f(w)
\]</span></p>
<p>梯度下降算法的描述公式: <span class="math display">\[
w:=w-\alpha \nabla f(w)
\]</span></p>
<p>这个梯度意味着要沿 x 的方向移动 <span class="math inline">\(\frac{\partial f(x,y)}{\partial x}\)</span> ，沿 y 的方向移动 <span class="math inline">\(\frac{\partial f(x,y)}{\partial y}\)</span> 。其中，函数<span class="math inline">\(f(x, y)\)</span>必须要在待计算的点上有定义并且可微。</p>
<p>梯度上升的一个示意图 <img src="https://suool-bolg.b0.upaiyun.com/2018/09/18/LR_8.png" alt="LR_8"></p>
<p>步长，记作 α , <span class="math inline">\(\nabla f(w)\)</span> 表示沿着梯度变化的方向</p>
<p>这个算法将会在很大的程度上被初始点的选择影响而陷入局部最小点。</p>
<h3 id="简单的线性分类器">简单的线性分类器</h3>
<p>代码示例-暂略</p>
<h2 id="多项逻辑斯谛回归模型">多项逻辑斯谛回归模型</h2>
<p>上述的都是二分类问题, 那么如何改造 logistics 回归解决多分类问题呢?</p>
<p>第一种方式是直接根据每个类别，都建立一个二分类器，带有这个类别的样本标记为1，带有其他类别的样本标记为0。假如我们有 K 个类别，最后我们就得到了 K 个针对不同标记的普通的logistic分类器。</p>
<p>第二种方式是修改 logistic 回归的损失函数，让其适应多分类问题。这个损失函数不再笼统地只考虑二分类非1就0的损失，而是具体考虑每个样本标记的损失。这种方法叫做 softmax 回归，即 logistic 回归的多分类版本。</p>
<p>首先对于第一种方式, 假如给定的的数据集 <span class="math inline">\(X \in R^{m\times n}\)</span>, 他们的标记为 <span class="math inline">\(Y \in R^k\)</span>, 即是政协样本有 K 个不同的类别。</p>
<p>现在我们挑选出数据集中标记为 <span class="math inline">\(c(c\leq k)\)</span> 的样本，将挑选出来的样本标记为1， 其余的所有不为 c 的样本标记为0，由此训练出一个 logistics回归二分分类器， 即得到 <span class="math inline">\(h_c(x)\)</span> （表示针对标记为 c 的 logistics 分类函数）</p>
<p>按照上面的步骤， 我们可以得到k个不同的分类器。针对一个分类样本，我们需要找到这个k个分类函数中输出值最大的那个， 即认为是测试样本的输出标记： <span class="math display">\[
\mathop{\arg\;\max}\limits_{c} h_c(x), c=1,2,\cdots,k
\]</span></p>
<p>第二种方式是 softmax 回归</p>
<p><span class="math display">\[
h_\theta(x^i) = 
\begin{bmatrix} 
p(y^i = 1 \mid x^i; \theta) 
\\ p(y^i = 2 \mid x^i; \theta) \\ 
\vdots \\
p(y^i = k \mid x^i; \theta)
\end{bmatrix} = \frac{1}{\sum_{c=1}^k e^{\theta_c^Tx^i}} 
\begin{bmatrix}
e^{\theta_1^Tx^i} \\
e^{\theta_2^Tx^i} \\
\vdots \\
e^{\theta_k^Tx^i}
\end{bmatrix}
\]</span></p>
<p>然后使用矩阵<span class="math inline">\(\theta\)</span>表示上式中的<span class="math inline">\(\theta_1,\cdots,\theta_k\)</span>,即是: <span class="math display">\[
\theta = \begin{bmatrix}
\theta_1^T \\
\theta_2^T \\
\vdots \\
\theta_k^T \\
\end{bmatrix}
\]</span></p>
<p>Softmax回归中将 <span class="math inline">\(\textstyle x\)</span> 分类为类别 <span class="math inline">\(\textstyle j\)</span> 的概率: <span class="math display">\[p(y^i=j\mid x^i;\theta) = \frac{e^{\theta_j^T}x^i}{\sum_{l=1}^k e_l^Tx^i}\]</span></p>
<p>一个图解: <img src="https://suool-bolg.b0.upaiyun.com/2018/09/18/15366230049078.jpg"></p>
<p><img src="https://suool-bolg.b0.upaiyun.com/2018/09/18/15366242666868.jpg"></p>
<h3 id="损失函数">损失函数</h3>
<p>为了训练模型，我们需要定义一个 loss function 来描述模型对问题的分类精度。loss 越小，代表模型的分类结果与真实值的偏差越小。在多分类问题中常使用交差熵作为损失函数，交叉熵定义如下，其中y代表真实值， <span class="math inline">\(\tilde{y}\)</span> 代表预测值，n代表需要区分的类别数。</p>
<p><span class="math display">\[
H_y(\tilde{y}) = - \sum_i^n y\log \tilde{y}
\]</span></p>
<p>那么，为什么交叉熵可以用来判断模型对真实概率分布 估计的准确程度呢？首先补充几个知识点</p>
<h4 id="信息量"><strong>信息量</strong></h4>
<p>直觉上来说：一件事情发生的可能性越小（概率小），当这件事发生时，人们所获得信息量越大；相反，一件事极有可能发生（概率大），当这件事发生时，人们会感觉没有什么信息量，因为早知道会发生。因此信息量跟事件发生的概率有关。定义如下，其中 <span class="math inline">\(p(x_{0})\)</span> 为事件 <span class="math inline">\(x_{0}\)</span> 发生的概率，log 为自然对数。</p>
<p><span class="math display">\[
I(x_0) = -log(p(x_0))
\]</span></p>
<p>由于是概率所以 <span class="math inline">\(p(x_{0})\)</span> 的取值范围是 [0,1],绘制为图，可见该函数符合我们对信息量的直觉</p>
<p><img src="https://suool-bolg.b0.upaiyun.com/2018/09/18/15366229765258.jpg"></p>
<h4 id="熵">熵</h4>
<p>对于某个事件，有n种可能性，每种可能性有个概率值。熵用来表示所有信息量的期望, 也是随机变量不确定性的度量, 其定义如下: <span class="math display">\[
H(X) = - \sum_i^n p(x_i)\log (p(x_i))
\]</span></p>
<p>由此可见, 熵只依赖与 X 的分布,与其取值大小无关,因此熵也可以直接记做: <span class="math display">\[
H(p) = - \sum_i^n p_i\log p_i
\]</span></p>
<p>熵越大, 随机变量的不确定性越大.</p>
<h4 id="相对熵kl散度">相对熵（KL散度）</h4>
<p>对同一个问题，用P、Q同时描述，用 KL 散度来衡量两个分布的差异。 <span class="math display">\[
D_{KL}(p||q)=\sum_{i}^{n}{}p(x_{i})log(\frac{p(x_{i})}{q(x_{i})})\\
\]</span> 在机器学习中，P往往用来表示真实的样本分布，比如[1,0,0]表示当前样本属于第一类。Q用来表示模型所预测的分布，比如[0.7,0.2,0.1]。当然Q越接近P越好，这样就说明预测值十分逼近真实值。也就是上式的 <span class="math inline">\(D_{KL}\)</span>的值越小越好。</p>
<h4 id="交差熵">交差熵</h4>
<p>对 <span class="math inline">\(D_{KL}(p||q)\)</span>公式进行变形：</p>
<p><span class="math display">\[
\begin{align}
D_{KL}(p||q) &amp;= \sum_{i}^{n}{p(x_{i})log(p(x_{i}))} - \sum_{i}^{n}{p(x_{i})log(q(x_{i}))} \\
&amp; = -H(p(x)) + [-\sum_{i}^{n}{p(x_{i})log(q(x_{i}))}]
\end{align}
\]</span></p>
<p>等式的前一部分恰巧就是p的熵，等式的后一部分，就是交叉熵：</p>
<p><span class="math display">\[
H(p,q) = - \sum_{i}^{n}{p(x_{i})log(q(x_{i}))}
\]</span></p>
<p>在机器学习中，我们需要评估 labels 和 predicts 之间的差距，使用 KL 散度刚刚好，即 <span class="math inline">\(D_{KL}(y||\tilde{y})\)</span> ，由于KL散度中的前一部分−H(y)不变，故在优化过程中，只需要关注交叉熵就可以了。所以一般在机器学习中直接用用交叉熵做loss，评估模型。</p>
<h3 id="识别数字实践">识别数字实践</h3>
<p>暂略</p>

      
    </div>

    
      


    

    
    
    

    

    
      
    
    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>感谢搬砖</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/qr-wechat.jpeg" alt="SuooL 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/qr-alipay.jpeg" alt="SuooL 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/25/problems-solved-listed/" rel="next" title="问题解决记录">
                <i class="fa fa-chevron-left"></i> 问题解决记录
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/10/07/feed-forward-neural-network-on-tf-and-pytorch/" rel="prev" title="全连接前向神经网络与手写数字的实践">
                全连接前向神经网络与手写数字的实践 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">SuooL</p>
              <p class="site-description motion-element" itemprop="description">胡振生写字的地方</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">44</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">17</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">26</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3N1b29s" title="GitHub &rarr; https://github.com/suool"><i class="fa fa-fw fa-github"></i>GitHub</span>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <span class="exturl" data-url="bWFpbHRvOmh1MTAyMDkzNTIxOUBnbWFpbC5jb20=" title="E-Mail &rarr; mailto:hu1020935219@gmail.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</span>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <span class="exturl" data-url="aHR0cDovL2RvdWJhbi5jb20vcGVvcGxlL3N1b29s" title="豆瓣 &rarr; http://douban.com/people/suool"><i class="fa fa-fw fa-globe"></i>豆瓣</span>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#引言"><span class="nav-number">1.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑斯谛回归模型"><span class="nav-number">2.</span> <span class="nav-text">逻辑斯谛回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#sigmoid-函数"><span class="nav-number">2.1.</span> <span class="nav-text">sigmoid 函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二项逻辑斯谛回归模型"><span class="nav-number">3.</span> <span class="nav-text">二项逻辑斯谛回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#参数求解之最大似然估计法"><span class="nav-number">3.1.</span> <span class="nav-text">参数求解之最大似然估计法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度上升算法"><span class="nav-number">3.2.</span> <span class="nav-text">梯度上升算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简单的线性分类器"><span class="nav-number">3.3.</span> <span class="nav-text">简单的线性分类器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多项逻辑斯谛回归模型"><span class="nav-number">4.</span> <span class="nav-text">多项逻辑斯谛回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数"><span class="nav-number">4.1.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#信息量"><span class="nav-number">4.1.1.</span> <span class="nav-text">信息量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#熵"><span class="nav-number">4.1.2.</span> <span class="nav-text">熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#相对熵kl散度"><span class="nav-number">4.1.3.</span> <span class="nav-text">相对熵（KL散度）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#交差熵"><span class="nav-number">4.1.4.</span> <span class="nav-text">交差熵</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#识别数字实践"><span class="nav-number">4.2.</span> <span class="nav-text">识别数字实践</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2013 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SuooL</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">141k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">5:51</span>
  
</div>


  <div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZw==">NexT.Muse</span> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  

  
  <script src="/js/src/scrollspy.js?v=6.6.0"></script>
<script src="/js/src/post-details.js?v=6.6.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  








  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>

  <script>
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: true,
        notify: false,
        appId: '5usifk9CwDO081OoaWOEWckx-gzGzoHsz',
        appKey: 'eGyonkL7T0t7fW3DlmM4NnPQ',
        placeholder: '留下点什么吧',
        avatar:'mm',
        meta:guest,
        pageSize:'10' || 10,
        visitor: false
    });
  </script>




  





  

  
  <script>
    
    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(counter.time + 1);
            })
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text('Counter not initialized! See more at console err msg.');
              console.error('ATTENTION! LeanCloud counter has security bug, see here how to solve it: https://github.com/theme-next/hexo-leancloud-counter-security. \n But you also can use LeanCloud without security, by set \'security\' option to \'false\'.');
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "yklxnryiir1hbibxgmomfcifj3d8nl19hu01hlebjx5rncjx")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "yklxnryiir1hbibxgmomfcifj3d8nl19hu01hlebjx5rncjx",
                'X-LC-Key': "pw34xu53fh6a7j1eat1gdbj16y6ratoqnd6xyy6uknvcn3ul",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

    
  


  
  

  

  

  
  <script src="/js/src/exturl.js?v=6.6.0"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  

  

  

</body>
</html>
