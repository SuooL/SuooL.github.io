<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
































<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.6.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.6.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.6.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.6.0" color="#222">









<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.6.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Introduction 命名实体识别作为自然语言处理领域中一项基础而关键的技术，被广泛应用于自然语言处理各个应用领域中，也是关系抽取、事件抽取、知识图谱、机器翻译、问答系统等诸多 NLP 任务的基础，其目标是对待识别文本中代表知识主体的命名实体（named entity, NE）进行标注。 命名实体一般指的是文本中具有特定意义或者指代性强的实体，通常包括人名、地名、组织机构名、日期时间、专有名词">
<meta name="keywords" content="词嵌入,词窗口,命名实体识别,浅层神经网络">
<meta property="og:type" content="article">
<meta property="og:title" content="基于浅层前馈神经网络和词窗口的命名实体识别实践">
<meta property="og:url" content="https://suool.net/2019/03/09/ner-nn-pytorch/index.html">
<meta property="og:site_name" content="SuooL&#39;s Blog">
<meta property="og:description" content="Introduction 命名实体识别作为自然语言处理领域中一项基础而关键的技术，被广泛应用于自然语言处理各个应用领域中，也是关系抽取、事件抽取、知识图谱、机器翻译、问答系统等诸多 NLP 任务的基础，其目标是对待识别文本中代表知识主体的命名实体（named entity, NE）进行标注。 命名实体一般指的是文本中具有特定意义或者指代性强的实体，通常包括人名、地名、组织机构名、日期时间、专有名词">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2019/03/09/15521014621112.jpg">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2019/03/09/0043B8E5-D58E-405E-9304-C1178547F0BF.png">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2019/03/09/E8C03BEC-739A-4300-AC6C-5C63A8F4B458.png">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2019/03/09/98F38B26-486F-44B1-B93E-DE14BDAA880D.png">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2019/03/09/AFF9F092-B8EE-43E1-98F9-07BE5E162010.png">
<meta property="og:image" content="https://suool-bolg.b0.upaiyun.com/2019/03/09/Screenshot%20from%202019-03-09%2014-10-14.png">
<meta property="og:updated_time" content="2019-03-09T06:59:01.715Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基于浅层前馈神经网络和词窗口的命名实体识别实践">
<meta name="twitter:description" content="Introduction 命名实体识别作为自然语言处理领域中一项基础而关键的技术，被广泛应用于自然语言处理各个应用领域中，也是关系抽取、事件抽取、知识图谱、机器翻译、问答系统等诸多 NLP 任务的基础，其目标是对待识别文本中代表知识主体的命名实体（named entity, NE）进行标注。 命名实体一般指的是文本中具有特定意义或者指代性强的实体，通常包括人名、地名、组织机构名、日期时间、专有名词">
<meta name="twitter:image" content="https://suool-bolg.b0.upaiyun.com/2019/03/09/15521014621112.jpg">



  <link rel="alternate" href="/atom.xml" title="SuooL's Blog" type="application/atom+xml">




  <link rel="canonical" href="https://suool.net/2019/03/09/ner-nn-pytorch/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>基于浅层前馈神经网络和词窗口的命名实体识别实践 | SuooL's Blog</title>
  




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-61498523-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-61498523-1');
</script>









  <noscript>
  <style>
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion .logo-line-before i { left: initial; }
    .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SuooL's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <h1 class="site-subtitle" itemprop="description">蛰伏于盛夏 藏华于当春</h1>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    

    

    <a href="/" rel="section">首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    

    

    <a href="/about/" rel="section">关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    

    

    <a href="/tags/" rel="section">标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    

    

    <a href="/categories/" rel="section">分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    

    

    <a href="/archives/" rel="section">归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-commonweal">

    
    
    

    

    <a href="/404.html" rel="section">公益 404</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://suool.net/2019/03/09/ner-nn-pytorch/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="SuooL">
      <meta itemprop="description" content="胡振生写字的地方">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SuooL's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">基于浅层前馈神经网络和词窗口的命名实体识别实践

              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-09 11:07:45 / 修改时间：14:59:01" itemprop="dateCreated datePublished" datetime="2019-03-09T11:07:45+08:00">2019-03-09</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/09/ner-nn-pytorch/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/2019/03/09/ner-nn-pytorch/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2019/03/09/ner-nn-pytorch/" class="leancloud_visitors" data-flag-title="基于浅层前馈神经网络和词窗口的命名实体识别实践">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数：</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">8.5k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">21 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="introduction">Introduction</h2>
<p>命名实体识别作为自然语言处理领域中一项基础而关键的技术，被广泛应用于自然语言处理各个应用领域中，也是关系抽取、事件抽取、知识图谱、机器翻译、问答系统等诸多 NLP 任务的基础，其目标是对待识别文本中代表知识主体的命名实体（named entity, NE）进行标注。</p>
<p>命名实体一般指的是文本中具有特定意义或者指代性强的实体，通常包括人名、地名、组织机构名、日期时间、专有名词等。而在知识图谱等研究的驱动下，NER 识别的实体范围进一步扩大到各个专业知识领域。</p>
<p>目前通用领域的命名实体识别方法有两种，分别是浅层机器学习的方法和深层神经网络的方法。</p>
<p>NER 研究的发展趋势如下图：</p>
<figure>
<img src="https://suool-bolg.b0.upaiyun.com/2019/03/09/15521014621112.jpg" alt="发展趋势"><figcaption>发展趋势</figcaption>
</figure>
<p>本文主要使用<code>词窗口</code>和<code>词嵌入</code>技术对文本数据输入样本进行数据化处理，主要是降维工作。</p>
<p>很显然命名实体识别本质是一个分类任务，因此本文模型搭建了一个简单的前馈神经网络来完成分类预测的任务。</p>
<p>最后经过验证，该模型具有一定的有效性，证明了这个模型基本上是可以成立的。</p>
<h2 id="相关工作">相关工作</h2>
<h3 id="词窗口">词窗口</h3>
<p>这里的词窗口和 n-gram 模型有一定的类似之处，本文处理的语料是中文语料，取一个合适的窗口大小，对输入语料进行对应的前后扩展，使其按照该窗口分割出的窗口词数目刚好等于原输入语料词数目，从而使每个窗口词对应一个实体标签，形成词窗口对。</p>
<p>这里处理的主要目的使用局部窗口的概念，来限定词义的预测范围，使词与其近邻的上下文产生一定的关联。</p>
<p>具体如下图: <img src="https://suool-bolg.b0.upaiyun.com/2019/03/09/0043B8E5-D58E-405E-9304-C1178547F0BF.png" alt="词窗口对"></p>
<p>上面显示了10组词窗口对，词窗口大小为5，因此每个样本有五个词，每个样本对应一个标签。</p>
<p>标签含义如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">人名 nr </span><br><span class="line">地名 ns</span><br><span class="line">机构名称 nt</span><br><span class="line">其他 o</span><br></pre></td></tr></table></figure>
<p><strong>本文处理的标签直接按照原始标签处理，没有转化为 BIO 标准的实体标注标签，由于标签体系过于简单，对于最后的准确率会有一定的影响</strong>。</p>
<h3 id="词嵌入">词嵌入</h3>
<p>NLP 与图像处理相比，其难点之一就在于自然语言不是天然数字量化的，图像可以使用各种数字标签直接转换，比如常见的 RGB、HSV等，这些数字量化的数据可以直接交给计算机处理。</p>
<p>而文字则不然，计算机并不认识文字，也无法将文字直接转换为合适的数学表示，因此，词嵌入技术便出现了。词嵌入就是描述的就是如何将主观的词用数字向量表示。</p>
<p>传统的方式有 <code>one-hot</code> ，但其问题在于既不能很好表示词义又存在维度灾难，相比起来词嵌入（<code>word-embedding</code>）是一种降维技术，他用相对紧凑较少的维度来表示词不同维度的特征。</p>
<p>本文使用的词嵌入使用的是 PyTorch 自带的 <code>torch.nn.Embedding(m, n)</code>函数实现。在本文中的词嵌入更像是一个随着神经网络训练产生的副产物，因为是随机初始化词嵌入向量的，不是预训练的词向量。</p>
<h3 id="前馈神经网络">前馈神经网络</h3>
<p>这个在之前的文章中已经有所介绍，此处就不在赘述了，本文所搭建的神经网络是一个非常简单的神经网络。</p>
<p>由于 NER 涉及的分类问题显然不是一个简单线性可分问题，因此直接使用线性回归模型是不可能解决的，</p>
<p>而神经网络的强大之处在于其能拟合任何函数，其关键之处在于加入非线性的因素，即是：激活函数。而这个线性嵌套非线性的过程叫激活，构成了隐藏层的神经元，这样的隐藏层越多，非线性越多，网络就越深，本文就用了两层。</p>
<p>然后输出层根据任务一般使用<code>softmax</code>多分类函数。</p>
<h2 id="模型定义">模型定义</h2>
<h3 id="总体网络架构">总体网络架构</h3>
<p>总体模型示意图如下： <img src="https://suool-bolg.b0.upaiyun.com/2019/03/09/E8C03BEC-739A-4300-AC6C-5C63A8F4B458.png" alt="E8C03BEC-739A-4300-AC6C-5C63A8F4B458"></p>
<p>可以看出一共有两层隐藏层，一个输入层和输出层。</p>
<p>模型定义代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WindowClassifier</span><span class="params">(nn.Module)</span>:</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, vocab_size, embedding_size, window_size, hidden_size, output_size)</span>:</span></span><br><span class="line"></span><br><span class="line">        super(WindowClassifier, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.embed = nn.Embedding(vocab_size, embedding_size)</span><br><span class="line">        self.h_layer1 = nn.Linear(embedding_size * (window_size * <span class="number">2</span> + <span class="number">1</span>), hidden_size)</span><br><span class="line">        self.h_layer2 = nn.Linear(hidden_size, hidden_size)</span><br><span class="line">        self.o_layer = nn.Linear(hidden_size, output_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.softmax = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">        self.dropout = nn.Dropout(<span class="number">0.35</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs, is_training=False)</span>:</span> </span><br><span class="line">        embeds = self.embed(inputs) <span class="comment"># BxWxD  torch.Size([128, 5, 100])</span></span><br><span class="line">        concated = embeds.view(<span class="number">-1</span>, embeds.size(<span class="number">1</span>)*embeds.size(<span class="number">2</span>)) <span class="comment"># Bx(W*D)</span></span><br><span class="line">        h0 = self.relu(self.h_layer1(concated))</span><br><span class="line">        <span class="keyword">if</span> is_training:</span><br><span class="line">            h0 = self.dropout(h0)</span><br><span class="line">        h1 = self.relu(self.h_layer2(h0))</span><br><span class="line">        <span class="keyword">if</span> is_training:</span><br><span class="line">            h1 = self.dropout(h1)</span><br><span class="line">        out = self.softmax(self.o_layer(h1))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>激活函数使用的是 ReLU，最终是个多分类任务，所以说 LogSoftmax 进行归一化处理。</p>
<h3 id="数据预处理">数据预处理</h3>
<p>原始语料格式如下所示： <img src="https://suool-bolg.b0.upaiyun.com/2019/03/09/98F38B26-486F-44B1-B93E-DE14BDAA880D.png" alt="语料"></p>
<p>这里需要将 word 和 tag 分别取出，形成序列，目标格式如下: <img src="https://suool-bolg.b0.upaiyun.com/2019/03/09/AFF9F092-B8EE-43E1-98F9-07BE5E162010.png" alt="格式"></p>
<p>从而方便生成处理窗口词对。</p>
<h2 id="实验代码">实验代码</h2>
<h3 id="导入环境">导入环境</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> sklearn_crfsuite <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="comment">### 预定义</span></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">random.seed(<span class="number">1024</span>)</span><br><span class="line">flatten = <span class="keyword">lambda</span> l: [item <span class="keyword">for</span> sublist <span class="keyword">in</span> l <span class="keyword">for</span> item <span class="keyword">in</span> sublist]</span><br><span class="line"></span><br><span class="line">USE_CUDA = torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">FloatTensor = torch.cuda.FloatTensor <span class="keyword">if</span> USE_CUDA <span class="keyword">else</span> torch.FloatTensor</span><br><span class="line">LongTensor = torch.cuda.LongTensor <span class="keyword">if</span> USE_CUDA <span class="keyword">else</span> torch.LongTensor</span><br><span class="line">ByteTensor = torch.cuda.ByteTensor <span class="keyword">if</span> USE_CUDA <span class="keyword">else</span> torch.ByteTensor</span><br></pre></td></tr></table></figure>
<h3 id="数据预处理-1">数据预处理</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_corpus</span><span class="params">(file_path, is_train = True)</span>:</span></span><br><span class="line">    data = []</span><br><span class="line">    <span class="keyword">if</span> is_train :</span><br><span class="line">        output_data = open(<span class="string">'./original/train_process.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        output_pkl = open(<span class="string">'train_data.pkl'</span>, <span class="string">'wb'</span>)</span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        output_data = open(<span class="string">'./original/test_process.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        output_pkl = open(<span class="string">'test_data.pkl'</span>, <span class="string">'wb'</span>)</span><br><span class="line">    </span><br><span class="line">    file = open(file_path, <span class="string">'r'</span>, encoding=<span class="string">'utf8'</span>)</span><br><span class="line">    lines = file.readlines()</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        <span class="comment"># 移除字符串的头和尾的空格并分割</span></span><br><span class="line">        word_list = line.strip().split()</span><br><span class="line">        cor_line = list(words.split(<span class="string">"/"</span>) <span class="keyword">for</span> words <span class="keyword">in</span> word_list)</span><br><span class="line">        sent, tag = list(zip(*cor_line))</span><br><span class="line">        data.append([sent, tag])</span><br><span class="line">        <span class="comment"># 持久化 Json 存储</span></span><br><span class="line">        output_data.write(<span class="string">"&#123;\"words\":\"%s\", \"tags\":\"%s\"&#125;"</span> % (<span class="string">" "</span>.join(sent), <span class="string">" "</span>.join(tag)))</span><br><span class="line">        output_data.write(<span class="string">"\n"</span>)</span><br><span class="line">    <span class="comment"># Pickle dictionary using protocol 0.</span></span><br><span class="line">    pickle.dump(data, output_pkl)</span><br><span class="line">    output_data.close()  </span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line">    </span><br><span class="line">train_data = preprocess_corpus(<span class="string">"./original/train1.txt"</span>)</span><br><span class="line"></span><br><span class="line">test_data =  preprocess_corpus(<span class="string">"./original/testright1.txt"</span>, is_train = <span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<h3 id="输入样本生成">输入样本生成</h3>
<ol type="1">
<li>词表、标签表及其映射</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sents, tags = list(zip(*train_data)) <span class="comment">#sent实际上就是句子序列组成的list，tags 是所有的标签 list</span></span><br><span class="line"><span class="comment"># 用集合去重</span></span><br><span class="line">vocab = list(set(flatten(sents)))</span><br><span class="line">tagset = list(set(flatten(tags)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 映射</span></span><br><span class="line"><span class="comment"># 词映射，&lt;UNK&gt; 为未登录词，&lt;DUMMY&gt; 为扩展填充词</span></span><br><span class="line">word2index=&#123;<span class="string">'&lt;UNK&gt;'</span> : <span class="number">0</span>, <span class="string">'&lt;DUMMY&gt;'</span> : <span class="number">1</span>&#125;<span class="keyword">for</span> vo <span class="keyword">in</span> vocab:</span><br><span class="line">    <span class="keyword">if</span> word2index.get(vo) <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        word2index[vo] = len(word2index)</span><br><span class="line">index2word = &#123;v:k <span class="keyword">for</span> k, v <span class="keyword">in</span> word2index.items()&#125;</span><br><span class="line"></span><br><span class="line">tag2index = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> tagset:</span><br><span class="line">    <span class="keyword">if</span> tag2index.get(tag) <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        tag2index[tag] = len(tag2index)</span><br><span class="line">index2tag=&#123;v:k <span class="keyword">for</span> k, v <span class="keyword">in</span> tag2index.items()&#125;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>生成窗口词对</li>
</ol>
<p>这一步的生成结果如文章开头的示意图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">WINDOW_SIZE = <span class="number">2</span></span><br><span class="line">windows_train = []</span><br><span class="line"><span class="keyword">for</span> sample <span class="keyword">in</span> train_data:  <span class="comment">#每一个sample就是完整的一句话以及对应的单词tag</span></span><br><span class="line">    dummy = [<span class="string">'&lt;DUMMY&gt;'</span>] * WINDOW_SIZE</span><br><span class="line">    window = list(nltk.ngrams(dummy + list(sample[<span class="number">0</span>]) + dummy, WINDOW_SIZE * <span class="number">2</span> + <span class="number">1</span>))</span><br><span class="line">    windows_train.extend([[list(window[i]), sample[<span class="number">1</span>][i]] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(sample[<span class="number">0</span>]))])</span><br><span class="line"></span><br><span class="line">windows_test = []</span><br><span class="line"><span class="keyword">for</span> sample <span class="keyword">in</span> test_data:  <span class="comment">#每一个sample就是完整的一句话以及对应的单词tag</span></span><br><span class="line">    dummy = [<span class="string">'&lt;DUMMY&gt;'</span>] * WINDOW_SIZE</span><br><span class="line">    window = list(nltk.ngrams(dummy + list(sample[<span class="number">0</span>]) + dummy, WINDOW_SIZE * <span class="number">2</span> + <span class="number">1</span>))</span><br><span class="line">    windows_test.extend([[list(window[i]), sample[<span class="number">1</span>][i]] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(sample[<span class="number">0</span>]))])</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>划分训练集、测试集</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里一个windows的含义就是一句话的窗口上下文标注对</span></span><br><span class="line">random.shuffle(windows_train)</span><br><span class="line">random.shuffle(windows_test)</span><br><span class="line"></span><br><span class="line">train_data = windows_train<span class="comment"># windows[:int(len(windows) * 0.9)]</span></span><br><span class="line">test_data = windows_test<span class="comment"># windows[int(len(windows) * 0.9):]</span></span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li>样本集 batch 生成函数</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getBatch</span><span class="params">(batch_size, train_data)</span>:</span></span><br><span class="line">    random.shuffle(train_data)</span><br><span class="line">    sindex = <span class="number">0</span></span><br><span class="line">    eindex = batch_size</span><br><span class="line">    <span class="keyword">while</span> eindex &lt; len(train_data):</span><br><span class="line">        batch = train_data[sindex: eindex]</span><br><span class="line">        temp = eindex</span><br><span class="line">        eindex = eindex + batch_size</span><br><span class="line">        sindex = temp</span><br><span class="line">        <span class="keyword">yield</span> batch</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> eindex &gt;= len(train_data):</span><br><span class="line">        batch = train_data[sindex:]</span><br><span class="line">        <span class="keyword">yield</span> batch</span><br></pre></td></tr></table></figure>
<h3 id="训练">训练</h3>
<ol type="1">
<li>词序列、标签映射数字转换</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_sequence</span><span class="params">(seq, word2index)</span>:</span></span><br><span class="line">    idxs = list(map(<span class="keyword">lambda</span> w: word2index[w] <span class="keyword">if</span> word2index.get(w) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">else</span> word2index[<span class="string">"&lt;UNK&gt;"</span>], seq))</span><br><span class="line">    <span class="keyword">return</span> Variable(LongTensor(idxs))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_tag</span><span class="params">(tag,tag2index)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> Variable(LongTensor([tag2index[tag]]))</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>模型超参数设置</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">128</span></span><br><span class="line">EMBEDDING_SIZE = <span class="number">100</span> <span class="comment"># x (WINDOW_SIZE*2+1) = 500</span></span><br><span class="line">HIDDEN_SIZE = <span class="number">300</span></span><br><span class="line">EPOCH = <span class="number">3</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.001</span></span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>训练</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">model = WindowClassifier(len(word2index), EMBEDDING_SIZE, WINDOW_SIZE, HIDDEN_SIZE, len(tag2index))</span><br><span class="line"><span class="keyword">if</span> USE_CUDA:</span><br><span class="line">    model = model.cuda()</span><br><span class="line">loss_function = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCH):</span><br><span class="line">    losses = []</span><br><span class="line">    <span class="keyword">for</span> i,batch <span class="keyword">in</span> enumerate(getBatch(BATCH_SIZE, train_data)):</span><br><span class="line">        x,y=list(zip(*batch))</span><br><span class="line">        inputs = torch.cat([prepare_sequence(sent, word2index).view(<span class="number">1</span>, <span class="number">-1</span>) <span class="keyword">for</span> sent <span class="keyword">in</span> x]) <span class="comment"># view是变成二维 这里是把batch绑起来一个矩阵</span></span><br><span class="line">        targets = torch.cat([prepare_tag(tag, tag2index) <span class="keyword">for</span> tag <span class="keyword">in</span> y])</span><br><span class="line">        model.zero_grad()</span><br><span class="line">        preds = model(inputs, is_training=<span class="keyword">True</span>)</span><br><span class="line">        loss = loss_function(preds, targets)</span><br><span class="line">        losses.append(loss.item())</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"[%d/%d] mean_loss : %0.2f"</span> %(epoch, EPOCH, np.mean(losses)))</span><br><span class="line">            losses = []</span><br><span class="line"><span class="comment"># 保存模型            </span></span><br><span class="line">torch.save(model.state_dict(), <span class="string">"./simplennmodel.pkl"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="测试及结果">测试及结果</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">for_f1_score = []</span><br><span class="line"></span><br><span class="line">accuracy = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> test <span class="keyword">in</span> test_data:</span><br><span class="line">    x, y = test[<span class="number">0</span>], test[<span class="number">1</span>]</span><br><span class="line">    input_ = prepare_sequence(x, word2index).view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    i = model(input_).max(<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">    pred = index2tag[i.data.tolist()[<span class="number">0</span>]]</span><br><span class="line">    for_f1_score.append([pred, y])</span><br><span class="line">    <span class="keyword">if</span> pred == y:</span><br><span class="line">        accuracy += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(accuracy/len(test_data) * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">y_pred, y_test = list(zip(*for_f1_score))</span><br><span class="line"></span><br><span class="line">sorted_labels = sorted(list(set(y_test) - &#123;<span class="string">'o'</span>&#125;), key=<span class="keyword">lambda</span> name: (name[<span class="number">1</span>:], name[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line">y_pred = [[y] <span class="keyword">for</span> y <span class="keyword">in</span> y_pred] <span class="comment"># this is because sklearn_crfsuite.metrics function flatten inputs</span></span><br><span class="line">y_test = [[y] <span class="keyword">for</span> y <span class="keyword">in</span> y_test]</span><br><span class="line"></span><br><span class="line">print(metrics.flat_classification_report(y_test, y_pred, labels = sorted_labels, digits=<span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p>输出结果如下: <img src="https://suool-bolg.b0.upaiyun.com/2019/03/09/Screenshot%20from%202019-03-09%2014-10-14.png" alt="Screenshot from 2019-03-09 14-10-14"></p>
<h2 id="next">Next</h2>
<p>这里的处理使用的是最直接的标签体系，神经网络模型的架构也比较简单，下一步计划将现有的预料数据标签体系转换为 BIO 标签，并搭建更为复杂的网络模型来尝试这一任务。</p>

      
    </div>

    
      


    

    
    
    

    

    
      
    
    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>感谢搬砖</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/qr-wechat.jpeg" alt="SuooL 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/qr-alipay.jpeg" alt="SuooL 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/命名实体识别/" rel="tag"># 命名实体识别</a>
          
            <a href="/tags/前馈神经网络/" rel="tag"># 前馈神经网络</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/01/optimization-problem/" rel="next" title="梯度下降算法及 PyTorch 的实现">
                <i class="fa fa-chevron-left"></i> 梯度下降算法及 PyTorch 的实现
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">SuooL</p>
              <p class="site-description motion-element" itemprop="description">胡振生写字的地方</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">47</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">17</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">32</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3N1b29s" title="GitHub &rarr; https://github.com/suool"><i class="fa fa-fw fa-github"></i>GitHub</span>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <span class="exturl" data-url="bWFpbHRvOmh1MTAyMDkzNTIxOUBnbWFpbC5jb20=" title="E-Mail &rarr; mailto:hu1020935219@gmail.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</span>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <span class="exturl" data-url="aHR0cDovL2RvdWJhbi5jb20vcGVvcGxlL3N1b29s" title="豆瓣 &rarr; http://douban.com/people/suool"><i class="fa fa-fw fa-globe"></i>豆瓣</span>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相关工作"><span class="nav-number">2.</span> <span class="nav-text">相关工作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#词窗口"><span class="nav-number">2.1.</span> <span class="nav-text">词窗口</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#词嵌入"><span class="nav-number">2.2.</span> <span class="nav-text">词嵌入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#前馈神经网络"><span class="nav-number">2.3.</span> <span class="nav-text">前馈神经网络</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型定义"><span class="nav-number">3.</span> <span class="nav-text">模型定义</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#总体网络架构"><span class="nav-number">3.1.</span> <span class="nav-text">总体网络架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据预处理"><span class="nav-number">3.2.</span> <span class="nav-text">数据预处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实验代码"><span class="nav-number">4.</span> <span class="nav-text">实验代码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#导入环境"><span class="nav-number">4.1.</span> <span class="nav-text">导入环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据预处理-1"><span class="nav-number">4.2.</span> <span class="nav-text">数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输入样本生成"><span class="nav-number">4.3.</span> <span class="nav-text">输入样本生成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练"><span class="nav-number">4.4.</span> <span class="nav-text">训练</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#测试及结果"><span class="nav-number">5.</span> <span class="nav-text">测试及结果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#next"><span class="nav-number">6.</span> <span class="nav-text">Next</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2013 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SuooL</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">161k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">6:42</span>
  
</div>


  <div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZw==">NexT.Muse</span> v6.6.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script src="/js/src/utils.js?v=6.6.0"></script>

  <script src="/js/src/motion.js?v=6.6.0"></script>



  
  

  
  <script src="/js/src/scrollspy.js?v=6.6.0"></script>
<script src="/js/src/post-details.js?v=6.6.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.6.0"></script>



  



  








  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>

  <script>
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: true,
        notify: false,
        appId: '5usifk9CwDO081OoaWOEWckx-gzGzoHsz',
        appKey: 'eGyonkL7T0t7fW3DlmM4NnPQ',
        placeholder: '留下点什么吧',
        avatar:'mm',
        meta:guest,
        pageSize:'10' || 10,
        visitor: false
    });
  </script>




  





  

  
  <script>
    
    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(counter.time + 1);
            })
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text('Counter not initialized! See more at console err msg.');
              console.error('ATTENTION! LeanCloud counter has security bug, see here how to solve it: https://github.com/theme-next/hexo-leancloud-counter-security. \n But you also can use LeanCloud without security, by set \'security\' option to \'false\'.');
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "yklxnryiir1hbibxgmomfcifj3d8nl19hu01hlebjx5rncjx")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "yklxnryiir1hbibxgmomfcifj3d8nl19hu01hlebjx5rncjx",
                'X-LC-Key': "pw34xu53fh6a7j1eat1gdbj16y6ratoqnd6xyy6uknvcn3ul",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
.MathJax_Display {
    overflow: auto hidden;
}
</style>

    
  


  
  

  

  

  
  <script src="/js/src/exturl.js?v=6.6.0"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  

  

  

</body>
</html>
